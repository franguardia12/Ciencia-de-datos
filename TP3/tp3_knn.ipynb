{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b53efb8",
      "metadata": {
        "id": "8b53efb8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "entrenamiento = pd.read_csv('train.csv')\n",
        "testeo = pd.read_csv('test.csv')\n",
        "muestra = pd.read_csv('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8867f817",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8867f817",
        "outputId": "4449ab57-0a65-4026-c3dd-cd82b3725faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_keyword(keyword):\n",
        "    if isinstance(keyword, str):\n",
        "        processed_keyword = keyword.replace('%20', '_')\n",
        "        return processed_keyword.strip().lower()\n",
        "    return keyword\n",
        "\n",
        "def preprocess_location(location):\n",
        "    if isinstance(location, str):\n",
        "        processed_location = location.replace('%20', '_')\n",
        "        return processed_location\n",
        "    return location\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    text = text.replace('!', ' EXCLAMATION ')\n",
        "    text = text.replace('?', ' QUESTION ')\n",
        "\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51afad4a",
      "metadata": {
        "id": "51afad4a"
      },
      "source": [
        "## Split entre entrenamiento y validación\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c463e164",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c463e164",
        "outputId": "e494f39d-8784-4120-9a21-bb2f5e42fb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño entrenamiento: (6090, 6)\n",
            "Tamaño validación: (1523, 6)\n"
          ]
        }
      ],
      "source": [
        "X = entrenamiento.drop(['target'], axis=1)\n",
        "y = entrenamiento['target']\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train = X_train.copy()\n",
        "X_validation = X_validation.copy()\n",
        "\n",
        "X_train['text_orig'] = X_train['text'].astype(str)\n",
        "X_validation['text_orig'] = X_validation['text'].astype(str)\n",
        "\n",
        "X_train['text'] = X_train['text'].apply(preprocess_text)\n",
        "X_validation['text'] = X_validation['text'].apply(preprocess_text)\n",
        "\n",
        "X_train['location'] = X_train['location'].apply(preprocess_location)\n",
        "X_validation['location'] = X_validation['location'].apply(preprocess_location)\n",
        "\n",
        "X_train['keyword'] = X_train['keyword'].apply(preprocess_keyword)\n",
        "X_validation['keyword'] = X_validation['keyword'].apply(preprocess_keyword)\n",
        "\n",
        "X_train['text_raw'] = X_train['text'].apply(lambda tokens: ' '.join(tokens))\n",
        "X_validation['text_raw'] = X_validation['text'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "print(f\"Tamaño entrenamiento: {X_train.shape}\")\n",
        "print(f\"Tamaño validación: {X_validation.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3e781a05",
      "metadata": {
        "id": "3e781a05"
      },
      "outputs": [],
      "source": [
        "knn_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'knn__n_neighbors': [5, 10, 15, 25, 35],\n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__metric': ['minkowski'],\n",
        "    'knn__p': [1, 2]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af0073e3",
      "metadata": {
        "id": "af0073e3"
      },
      "source": [
        "## Búsqueda de hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "3a9d72cc",
      "metadata": {
        "id": "3a9d72cc"
      },
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=knn_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1',\n",
        "    cv=skf,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpYOrIJUAAfA",
        "outputId": "998fbcd6-fb86-4ead-df6c-85c9b14e7c03"
      },
      "id": "bpYOrIJUAAfA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "054adb2a",
      "metadata": {
        "id": "054adb2a"
      },
      "source": [
        "## Embedding del texto\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "34b6f5a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34b6f5a2",
        "outputId": "4be35d63-6f2c-4472-a071-f9f2ca6b5b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings 'glove-twitter-50' cargados (50 dimensiones)\n",
            "Embeddings entrenamiento: (6090, 50)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "word_vectors = None\n",
        "embedding_dim = 50\n",
        "model_name = 'glove-twitter-50'\n",
        "\n",
        "try:\n",
        "    from gensim.downloader import load\n",
        "    word_vectors = load(model_name)\n",
        "    embedding_dim = word_vectors.vector_size\n",
        "    print(f\"Embeddings '{model_name}' cargados ({embedding_dim} dimensiones)\")\n",
        "except Exception as exc:\n",
        "    print(f\"No se pudieron cargar embeddings pre-entrenados: {exc}\")\n",
        "    word_vectors = None\n",
        "\n",
        "def text_to_embedding(tokens, word_vectors, embedding_dim):\n",
        "    if word_vectors is None:\n",
        "        return np.zeros(embedding_dim)\n",
        "    vectors = []\n",
        "    for word in tokens:\n",
        "        if word in word_vectors:\n",
        "            vectors.append(word_vectors[word])\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    return np.zeros(embedding_dim)\n",
        "\n",
        "X_train_embeddings = np.vstack([\n",
        "    text_to_embedding(tokens, word_vectors, embedding_dim)\n",
        "    for tokens in X_train['text']\n",
        "])\n",
        "X_validation_embeddings = np.vstack([\n",
        "    text_to_embedding(tokens, word_vectors, embedding_dim)\n",
        "    for tokens in X_validation['text']\n",
        "])\n",
        "\n",
        "print(f\"Embeddings entrenamiento: {X_train_embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "e2057f6d",
      "metadata": {
        "id": "e2057f6d",
        "outputId": "a0074e6b-4443-4225-9581-a31ef10a86df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF reducido entrenamiento: (6090, 200)\n"
          ]
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer(\n",
        "    max_features=None,\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=2,\n",
        "    max_df=0.90\n",
        ")\n",
        "svd = TruncatedSVD(n_components=200, random_state=42)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train['text_raw'])\n",
        "X_validation_tfidf = tfidf.transform(X_validation['text_raw'])\n",
        "\n",
        "X_train_tfidf_svd = svd.fit_transform(X_train_tfidf)\n",
        "X_validation_tfidf_svd = svd.transform(X_validation_tfidf)\n",
        "\n",
        "print(f\"TF-IDF reducido entrenamiento: {X_train_tfidf_svd.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48b0bccc",
      "metadata": {
        "id": "48b0bccc"
      },
      "source": [
        "## Entrenamiento del modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "ad28a27b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad28a27b",
        "outputId": "3c1758be-7411-41da-958d-07635fd94a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz final entrenamiento: (6090, 50)\n",
            "Matriz final validación: (1523, 50)\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Mejores hiperparámetros:\n",
            "{'knn__metric': 'minkowski', 'knn__n_neighbors': 35, 'knn__p': 2, 'knn__weights': 'distance'}\n",
            "Mejor F1 (CV): 0.7600\n"
          ]
        }
      ],
      "source": [
        "X_train_final = np.hstack([X_train_embeddings])\n",
        "X_validation_final = np.hstack([ X_validation_embeddings])\n",
        "\n",
        "X_train_final = np.nan_to_num(X_train_final)\n",
        "X_validation_final = np.nan_to_num(X_validation_final)\n",
        "\n",
        "print(f\"Matriz final entrenamiento: {X_train_final.shape}\")\n",
        "print(f\"Matriz final validación: {X_validation_final.shape}\")\n",
        "\n",
        "grid.fit(X_train_final, y_train)\n",
        "\n",
        "print('Mejores hiperparámetros:')\n",
        "print(grid.best_params_)\n",
        "print(f\"Mejor F1 (CV): {grid.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57230993",
      "metadata": {
        "id": "57230993"
      },
      "source": [
        "## Evaluación del modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2681406b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2681406b",
        "outputId": "f8777c7a-67e2-4c6a-9e13-a013b70590bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 validacion: 0.7814\n",
            "F1 entrenamiento: 0.9840\n",
            "Gap: 0.2026\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "y_pred_validation = grid.predict(X_validation_final)\n",
        "y_pred_train = grid.predict(X_train_final)\n",
        "\n",
        "print(f\"F1 validacion: {f1_score(y_validation, y_pred_validation):.4f}\")\n",
        "print(f\"F1 entrenamiento: {f1_score(y_train, y_pred_train):.4f}\")\n",
        "print(f\"Gap: {f1_score(y_train, y_pred_train) - f1_score(y_validation, y_pred_validation):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "val_proba = best_model.predict_proba(X_validation_final)[:, 1]\n",
        "\n",
        "thresholds = np.linspace(0.01, 0.99, 200)\n",
        "f1_scores = [(thr, f1_score(y_validation, (val_proba >= thr).astype(int)))\n",
        "             for thr in thresholds]\n",
        "\n",
        "best_thr, best_f1 = max(f1_scores, key=lambda x: x[1])\n",
        "\n",
        "print(f\"Best threshold on validation: {best_thr:.3f}\")\n",
        "print(f\"F1 on validation with best threshold: {best_f1:.4f}\")\n",
        "\n",
        "def predict_with_threshold(model, X, thr=best_thr):\n",
        "    proba = model.predict_proba(X)[:, 1]\n",
        "    return (proba >= thr).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQkYM_b43xTG",
        "outputId": "07bfa253-8102-4ca1-af30-920e9e7341d2"
      },
      "id": "PQkYM_b43xTG",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold on validation: 0.517\n",
            "F1 on validation with best threshold: 0.7808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71106b88",
      "metadata": {
        "id": "71106b88"
      },
      "source": [
        "## Predicciones en el conjunto de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "7322c22e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7322c22e",
        "outputId": "e02cb67f-876a-4ec0-d8af-8a0ae6bf40db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz final test: (3263, 50)\n",
            "Submission guardado: 3263 predicciones\n",
            "Distribucion - 0: 1960, 1: 1303\n"
          ]
        }
      ],
      "source": [
        "testeo_processed = testeo.copy()\n",
        "\n",
        "testeo_processed['text_orig'] = testeo_processed['text'].astype(str)\n",
        "testeo_processed['text'] = testeo_processed['text'].apply(preprocess_text)\n",
        "testeo_processed['keyword'] = testeo_processed['keyword'].apply(preprocess_keyword)\n",
        "testeo_processed['location'] = testeo_processed['location'].apply(preprocess_location)\n",
        "testeo_processed['text_raw'] = testeo_processed['text'].apply(lambda tokens: ' '.join(tokens))\n",
        "\n",
        "testeo_processed['keyword'] = testeo_processed['keyword'].fillna('unknown')\n",
        "testeo_processed['location'] = testeo_processed['location'].fillna('unknown')\n",
        "\n",
        "X_test_embeddings = np.vstack([\n",
        "    text_to_embedding(tokens, word_vectors, embedding_dim)\n",
        "    for tokens in testeo_processed['text']\n",
        "])\n",
        "\n",
        "X_test_final = np.hstack([X_test_embeddings])\n",
        "\n",
        "X_test_final = np.nan_to_num(X_test_final)\n",
        "\n",
        "print(f\"Matriz final test: {X_test_final.shape}\")\n",
        "\n",
        "y_pred_test = grid.predict(X_test_final)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'id': testeo['id'],\n",
        "    'target': y_pred_test\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_knn.csv', index=False)\n",
        "print(f\"Submission guardado: {len(y_pred_test)} predicciones\")\n",
        "print(f\"Distribucion - 0: {(y_pred_test == 0).sum()}, 1: {(y_pred_test == 1).sum()}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}