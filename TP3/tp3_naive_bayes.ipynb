{"cells":[{"cell_type":"code","execution_count":1,"id":"62431399","metadata":{"id":"62431399","executionInfo":{"status":"ok","timestamp":1763473901667,"user_tz":180,"elapsed":1538,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","\n","np.random.seed(5)\n","\n","entrenamiento = pd.read_csv('train.csv')\n","testeo = pd.read_csv('test.csv')\n","muestra = pd.read_csv('sample_submission.csv')"]},{"cell_type":"code","execution_count":2,"id":"362e42cb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"362e42cb","outputId":"99914d79-8791-4748-9e52-dbb9db547f40","executionInfo":{"status":"ok","timestamp":1763473910901,"user_tz":180,"elapsed":1933,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import re\n","import string\n","import nltk\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","def preprocess_keyword(keyword):\n","    if isinstance(keyword, str):\n","        processed_keyword = keyword.replace('%20', '_')\n","        return processed_keyword\n","    return keyword\n","\n","def preprocess_location(location):\n","    if isinstance(location, str):\n","        processed_location = location.replace('%20', '_')\n","        return processed_location\n","    return location\n","\n","def preprocess_text(text):\n","    text = text.lower()\n","\n","    text = re.sub(r'http\\S+|www\\.\\S+', ' URL ', text)\n","\n","    text = text.replace('!', ' EXCLAMATION ').replace('?', ' QUESTION ')\n","\n","    keep = set('#@')\n","    drop = ''.join(ch for ch in string.punctuation if ch not in keep)\n","    text = text.translate(str.maketrans('', '', drop))\n","\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text"]},{"cell_type":"markdown","id":"e2f2ffb7","metadata":{"id":"e2f2ffb7"},"source":["## Split entre entrenamiento y validación"]},{"cell_type":"code","execution_count":3,"id":"aaaaa142","metadata":{"id":"aaaaa142","executionInfo":{"status":"ok","timestamp":1763473919275,"user_tz":180,"elapsed":372,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[],"source":["entrenamiento['text'] = entrenamiento['text'].apply(preprocess_text)\n","entrenamiento['keyword'] = entrenamiento['keyword'].apply(preprocess_keyword)\n","entrenamiento['location'] = entrenamiento['location'].apply(preprocess_location)\n","\n","X = entrenamiento.drop(['target'], axis=1)\n","y = entrenamiento['target']\n","\n","X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.10, stratify=y, random_state=5)"]},{"cell_type":"markdown","id":"e2f636d9","metadata":{"id":"e2f636d9"},"source":["## Búsqueda de hiperparámetros"]},{"cell_type":"code","execution_count":4,"id":"78f10254","metadata":{"id":"78f10254","executionInfo":{"status":"ok","timestamp":1763473926858,"user_tz":180,"elapsed":4,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[],"source":["from sklearn.naive_bayes import ComplementNB\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import f1_score, make_scorer\n","from sklearn.model_selection import StratifiedKFold\n","\n","naive_model = ComplementNB()\n","\n","param_grid = {\n","    'alpha': np.logspace(-3, 1, 12),\n","    'fit_prior': [True, False],\n","    'norm': [True, False]\n","}\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","\n","grid = GridSearchCV(\n","    estimator=naive_model,\n","    param_grid=param_grid,\n","    scoring=make_scorer(f1_score),\n","    cv=cv,\n","    n_jobs=-1,\n","    verbose=0\n",")"]},{"cell_type":"markdown","id":"2cf5f8d4","metadata":{"id":"2cf5f8d4"},"source":["## Creación de features numéricas"]},{"cell_type":"code","execution_count":5,"id":"161c2c52","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"161c2c52","outputId":"9d9bdcc1-5323-46de-f6bd-3c7541832842","executionInfo":{"status":"ok","timestamp":1763473946334,"user_tz":180,"elapsed":83,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Features numéricas creadas:\n","      text_length  word_count  hashtag_count  exclamation_count\n","5286           77          16              0                  0\n","3193          121          18              3                  0\n","5272           72          12              1                  0\n","6816          111          17              0                  0\n","2996          112          20              0                  0\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-718284583.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  df_copy['has_time_reference']= t.str.contains(r'\\b(now|today|tonight|yesterday|urgent|breaking)\\b').astype(int)\n","/tmp/ipython-input-718284583.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  df_copy['elongated_token'] = t.str.contains(r'(.)\\1\\1+').astype(int)\n","/tmp/ipython-input-718284583.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  df_copy['has_time_reference']= t.str.contains(r'\\b(now|today|tonight|yesterday|urgent|breaking)\\b').astype(int)\n","/tmp/ipython-input-718284583.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  df_copy['elongated_token'] = t.str.contains(r'(.)\\1\\1+').astype(int)\n"]}],"source":["def create_numeric_features(df):\n","    df_copy = df.copy()\n","    t = df_copy['text'].astype(str)\n","\n","    df_copy['text_length']      = t.str.len()\n","    df_copy['word_count']       = t.str.split().str.len()\n","    df_copy['hashtag_count']    = t.str.count('#')\n","    df_copy['mention_count']    = t.str.count('@')\n","    df_copy['url_count']        = t.str.count(r'\\burl\\b')\n","    df_copy['exclamation_count']= t.str.count(r'\\bexclamation\\b')\n","    df_copy['question_count']   = t.str.count(r'\\bquestion\\b')\n","    df_copy['caps_word_count']  = 0\n","    df_copy['unique_word_ratio']= t.apply(lambda x: len(set(x.split()))/max(1,len(x.split())))\n","    df_copy['avg_word_length']  = t.apply(lambda x: (sum(len(w) for w in x.split())/max(1,len(x.split()))))\n","    df_copy['has_numbers']      = t.str.contains(r'\\d').astype(int)\n","    df_copy['has_time_reference']= t.str.contains(r'\\b(now|today|tonight|yesterday|urgent|breaking)\\b').astype(int)\n","\n","    disaster_keywords = ['fire','burn','crash','kill','dead','destroy','emergency','evacuate','disaster','damage']\n","    df_copy['disaster_word_count'] = t.apply(lambda x: sum(kw in x for kw in disaster_keywords))\n","\n","    df_copy['elongated_token'] = t.str.contains(r'(.)\\1\\1+').astype(int)\n","    return df_copy\n","\n","X_train = create_numeric_features(X_train)\n","X_validation = create_numeric_features(X_validation)\n","\n","print(\"Features numéricas creadas:\")\n","print(X_train[['text_length', 'word_count', 'hashtag_count', 'exclamation_count']].head())"]},{"cell_type":"markdown","id":"c8814209","metadata":{"id":"c8814209"},"source":["## Creación de features categóricas"]},{"cell_type":"code","execution_count":6,"id":"24421f4d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24421f4d","outputId":"a4b9de3e-180b-468d-a5a3-2ba83f78add9","executionInfo":{"status":"ok","timestamp":1763473956763,"user_tz":180,"elapsed":8,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Features categóricas creadas:\n","             keyword     location  has_keyword  has_location\n","5286        outbreak  no_location            1             0\n","3193  emergency_plan      Indiana            1             1\n","5272       oil_spill  no_location            1             0\n","6816         trapped      Orlando            1             1\n","2996      dust_storm  Lubbock, TX            1             1\n"]}],"source":["def create_categorical_features(df):\n","    df_copy = df.copy()\n","\n","    df_copy['keyword'] = df_copy['keyword'].fillna('no_keyword')\n","    df_copy['location'] = df_copy['location'].fillna('no_location')\n","\n","    df_copy['has_keyword'] = (df_copy['keyword'] != 'no_keyword').astype(int)\n","    df_copy['has_location'] = (df_copy['location'] != 'no_location').astype(int)\n","\n","    return df_copy\n","\n","X_train = create_categorical_features(X_train)\n","X_validation = create_categorical_features(X_validation)\n","\n","print(\"\\nFeatures categóricas creadas:\")\n","print(X_train[['keyword', 'location', 'has_keyword', 'has_location']].head())"]},{"cell_type":"markdown","id":"06b64da9","metadata":{"id":"06b64da9"},"source":["## Embedding del texto"]},{"cell_type":"code","execution_count":7,"id":"9e957b64","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e957b64","outputId":"4da4713c-30f7-48fb-f8d5-50d4b0148574","executionInfo":{"status":"ok","timestamp":1763473968963,"user_tz":180,"elapsed":1557,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using stop_words: None\n","\n","TF-IDF matrix shape: (6851, 22330)\n","Vocabulario de 22330 palabras\n"]}],"source":["from sklearn.model_selection import ParameterGrid\n","\n","X_train['text_str'] = X_train['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n","X_validation['text_str'] = X_validation['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n","\n","tfidf = TfidfVectorizer(\n","    max_features=None,\n","    min_df=2,\n","    max_df=0.90,\n","    ngram_range=(1, 3),\n","    sublinear_tf=True,\n","    lowercase=True,\n","    strip_accents='unicode',\n","    analyzer='word',\n","    norm='l2',\n","    use_idf=True,\n","    stop_words=None\n",")\n","\n","char_tfidf = TfidfVectorizer(\n","    analyzer='char_wb',\n","    ngram_range=(3, 6),\n","    min_df=3,\n","    sublinear_tf=True,\n","    lowercase=True,\n","    strip_accents='unicode'\n",")\n","\n","param_grid_nb = {\n","    'alpha': np.logspace(-3, 1, 12),\n","    'fit_prior': [True, False],\n","    'norm': [True, False]\n","}\n","param_grid_vec = [\n","    {'tfidf_stop': 'none'},\n","    {'tfidf_stop': 'english'}\n","]\n","\n","selected_stop_words_option = 'none'\n","\n","tfidf.stop_words = None if selected_stop_words_option == 'none' else 'english'\n","print(f\"Using stop_words: {tfidf.stop_words}\")\n","\n","X_train_tfidf = tfidf.fit_transform(X_train['text_str'])\n","X_validation_tfidf = tfidf.transform(X_validation['text_str'])\n","\n","X_train_char = char_tfidf.fit_transform(X_train['text_str'])\n","X_validation_char = char_tfidf.transform(X_validation['text_str'])\n","\n","print(f\"\\nTF-IDF matrix shape: {X_train_tfidf.shape}\")\n","print(f\"Vocabulario de {len(tfidf.vocabulary_)} palabras\")"]},{"cell_type":"markdown","id":"858ea0fa","metadata":{"id":"858ea0fa"},"source":["## One Hot Encoding"]},{"cell_type":"code","source":["from scipy.sparse import csr_matrix\n","\n","TOPK = 200\n","top_keywords = X_train['keyword'].value_counts().head(TOPK).index\n","X_train_kw = X_train['keyword'].where(X_train['keyword'].isin(top_keywords), 'OTHER')\n","X_val_kw   = X_validation['keyword'].where(X_validation['keyword'].isin(top_keywords), 'OTHER')\n","\n","kw_train_dum = pd.get_dummies(X_train_kw, prefix='kw', drop_first=False)\n","kw_val_dum   = pd.get_dummies(X_val_kw,   prefix='kw', drop_first=False)\n","\n","missing_cols = set(kw_train_dum.columns) - set(kw_val_dum.columns)\n","for c in missing_cols:\n","    kw_val_dum[c] = 0\n","kw_val_dum = kw_val_dum[kw_train_dum.columns]\n","\n","KW_train = csr_matrix(kw_train_dum.values.astype(int))\n","KW_val   = csr_matrix(kw_val_dum.values.astype(int))\n","\n","print(\"Keyword OHE (capped) shapes:\", KW_train.shape, KW_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SY04EpYyOHMo","outputId":"82e29e82-3d13-4dac-d1b7-530f1c7b28ec","executionInfo":{"status":"ok","timestamp":1763473979028,"user_tz":180,"elapsed":9,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"id":"SY04EpYyOHMo","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Keyword OHE (capped) shapes: (6851, 201) (762, 201)\n"]}]},{"cell_type":"markdown","id":"5bbe0dbc","metadata":{"id":"5bbe0dbc"},"source":["## Mean Encoding"]},{"cell_type":"code","execution_count":9,"id":"8b9319c4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8b9319c4","outputId":"ebc4aa2e-3eb8-4d49-b374-57acd8ad1227","executionInfo":{"status":"ok","timestamp":1763473994155,"user_tz":180,"elapsed":7554,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Mean Encoding aplicado a location y keyword\n","                        location  location_mean_encoded            keyword  \\\n","5286                 no_location               0.423231           outbreak   \n","3193                     Indiana               0.402861     emergency_plan   \n","5272                 no_location               0.423231          oil_spill   \n","6816                     Orlando               0.422674            trapped   \n","2996                 Lubbock, TX               0.439067         dust_storm   \n","5438                 no_location               0.423231             police   \n","1203  KurveZ@GearHeadCentral.net               0.422674  buildings_burning   \n","3712                 no_location               0.423231               fear   \n","983                     New York               0.326265           body_bag   \n","3148            Indianapolis, IN               0.431985          emergency   \n","\n","      keyword_mean_encoded  \n","5286              0.632076  \n","3193              0.497642  \n","5272              0.613001  \n","6816              0.386479  \n","2996              0.513506  \n","5438              0.487054  \n","1203              0.525089  \n","3712              0.324033  \n","983               0.291121  \n","3148              0.412586  \n"]}],"source":["location_means = X_train.join(y_train).groupby('location')['target'].mean()\n","\n","keyword_means = X_train.join(y_train).groupby('keyword')['target'].mean()\n","\n","global_mean = y_train.mean()\n","smoothing = 60\n","\n","def mean_encode_with_smoothing(value, means_dict, global_mean, smoothing, df_ref, col_name):\n","    if value in means_dict:\n","        count = (df_ref[col_name] == value).sum()\n","        return (means_dict[value] * count + global_mean * smoothing) / (count + smoothing)\n","    return global_mean\n","\n","X_train['location_mean_encoded'] = X_train['location'].apply(\n","    lambda x: mean_encode_with_smoothing(x, location_means, global_mean, smoothing, X_train, 'location')\n",")\n","\n","X_validation['location_mean_encoded'] = X_validation['location'].apply(\n","    lambda x: mean_encode_with_smoothing(x, location_means, global_mean, smoothing, X_train, 'location')\n",")\n","\n","X_train['keyword_mean_encoded'] = X_train['keyword'].apply(\n","    lambda x: mean_encode_with_smoothing(x, keyword_means, global_mean, smoothing, X_train, 'keyword')\n",")\n","\n","X_validation['keyword_mean_encoded'] = X_validation['keyword'].apply(\n","    lambda x: mean_encode_with_smoothing(x, keyword_means, global_mean, smoothing, X_train, 'keyword')\n",")\n","\n","print(f\"\\nMean Encoding aplicado a location y keyword\")\n","print(X_train[['location', 'location_mean_encoded', 'keyword', 'keyword_mean_encoded']].head(10))"]},{"cell_type":"markdown","id":"3e170f8b","metadata":{"id":"3e170f8b"},"source":["## Entrenamiento del modelo"]},{"cell_type":"code","execution_count":10,"id":"d88f324d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d88f324d","outputId":"de7867aa-5c4f-4cd3-d9dc-46b47a1d49be","executionInfo":{"status":"ok","timestamp":1763474014999,"user_tz":180,"elapsed":5910,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dimensiones finales del conjunto de entrenamiento: (6851, 69199)\n","Dimensiones finales del conjunto de validación: (762, 69199)\n","After chi2 selection: (6851, 69199) (762, 69199)\n","\n","Entrenando modelo con GridSearchCV...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:262: UserWarning: Feature 6 is constant and will be replaced with 0.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 9 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 10 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_discretization.py:306: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 11 are removed. Consider decreasing the number of bins.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_univariate_selection.py:783: UserWarning: k=100000 is greater than n_features=69199. All the features will be returned.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Mejores parámetros: {'alpha': np.float64(0.3511191734215131), 'fit_prior': True, 'norm': False}\n","Mejor score F1 (CV): 0.8167\n"]}],"source":["from scipy.sparse import hstack, csr_matrix\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.feature_selection import SelectKBest, chi2\n","\n","numeric_features = ['text_length', 'word_count', 'hashtag_count', 'mention_count',\n","                   'exclamation_count', 'question_count', 'caps_word_count',\n","                   'unique_word_ratio', 'avg_word_length',\n","                   'has_keyword', 'has_location',\n","                   'location_mean_encoded', 'keyword_mean_encoded']\n","\n","kbd = KBinsDiscretizer(n_bins=5, encode='onehot', strategy='quantile')\n","\n","X_train_num_binned = kbd.fit_transform(X_train[numeric_features].values)\n","X_val_num_binned   = kbd.transform(X_validation[numeric_features].values)\n","\n","X_train_combined = hstack([\n","    X_train_tfidf,\n","    X_train_char,\n","    KW_train,\n","    X_train_num_binned])\n","\n","X_validation_combined = hstack([\n","    X_validation_tfidf,\n","    X_validation_char,\n","    KW_val,\n","    X_val_num_binned])\n","\n","print(f\"\\nDimensiones finales del conjunto de entrenamiento: {X_train_combined.shape}\")\n","print(f\"Dimensiones finales del conjunto de validación: {X_validation_combined.shape}\")\n","\n","selector = SelectKBest(score_func=chi2, k=100000)\n","X_train_sel = selector.fit_transform(X_train_combined, y_train)\n","X_val_sel   = selector.transform(X_validation_combined)\n","\n","print(\"After chi2 selection:\", X_train_sel.shape, X_val_sel.shape)\n","\n","X_train_combined = X_train_sel\n","X_validation_combined = X_val_sel\n","\n","print(\"\\nEntrenando modelo con GridSearchCV...\")\n","grid.fit(X_train_combined, y_train)\n","\n","print(f\"\\nMejores parámetros: {grid.best_params_}\")\n","print(f\"Mejor score F1 (CV): {grid.best_score_:.4f}\")\n","\n","best_model = grid.best_estimator_"]},{"cell_type":"markdown","id":"2f10382c","metadata":{"id":"2f10382c"},"source":["## Evaluación del modelo"]},{"cell_type":"code","source":["print(f\"Mejores parámetros: {grid.best_params_}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aktTJ8l2A59F","outputId":"611c2ceb-c327-4e6c-eca6-80f3d334a359","executionInfo":{"status":"ok","timestamp":1763474023454,"user_tz":180,"elapsed":7,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"id":"aktTJ8l2A59F","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mejores parámetros: {'alpha': np.float64(0.3511191734215131), 'fit_prior': True, 'norm': False}\n"]}]},{"cell_type":"code","execution_count":12,"id":"b4228666","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4228666","outputId":"eaddbc3d-792c-4b6e-8f9b-12dd18d5afc2","executionInfo":{"status":"ok","timestamp":1763474030669,"user_tz":180,"elapsed":59,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Reconstructed X_validation_combined shape: (762, 69199)\n","Reporte de clasificación:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.90      0.86       435\n","           1       0.84      0.75      0.79       327\n","\n","    accuracy                           0.83       762\n","   macro avg       0.83      0.82      0.83       762\n","weighted avg       0.83      0.83      0.83       762\n","\n","\n","Matriz de confusión:\n","[[390  45]\n"," [ 83 244]]\n","\n","F1-Score en validación: 0.7922\n","\n","Reporte de clasificación (conjunto de entrenamiento):\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.95      0.91      3907\n","           1       0.93      0.82      0.87      2944\n","\n","    accuracy                           0.90      6851\n","   macro avg       0.90      0.89      0.89      6851\n","weighted avg       0.90      0.90      0.89      6851\n","\n","\n","Matriz de confusión (conjunto de entrenamiento):\n","[[3715  192]\n"," [ 526 2418]]\n","\n","F1-Score en entrenamiento: 0.8707\n"]}],"source":["from sklearn.metrics import classification_report, confusion_matrix, f1_score\n","from scipy.sparse import hstack, csr_matrix\n","\n","X_validation_combined_raw = hstack([\n","    X_validation_tfidf,\n","    X_validation_char,\n","    KW_val,\n","    X_val_num_binned])\n","\n","X_validation_combined = selector.transform(X_validation_combined_raw)\n","\n","print(f\"\\nReconstructed X_validation_combined shape: {X_validation_combined.shape}\")\n","\n","y_pred_validation = best_model.predict(X_validation_combined)\n","y_pred_training = best_model.predict(X_train_combined)\n","\n","print(\"Reporte de clasificación:\")\n","print(classification_report(y_validation, y_pred_validation))\n","\n","print(\"\\nMatriz de confusión:\")\n","print(confusion_matrix(y_validation, y_pred_validation))\n","\n","print(f\"\\nF1-Score en validación: {f1_score(y_validation, y_pred_validation):.4f}\")\n","\n","print(\"\\nReporte de clasificación (conjunto de entrenamiento):\")\n","print(classification_report(y_train, y_pred_training))\n","\n","print(\"\\nMatriz de confusión (conjunto de entrenamiento):\")\n","print(confusion_matrix(y_train, y_pred_training))\n","\n","print(f\"\\nF1-Score en entrenamiento: {f1_score(y_train, y_pred_training):.4f}\")"]},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","import numpy as np\n","\n","val_proba = best_model.predict_proba(X_validation_combined)[:, 1]\n","\n","thresholds = np.linspace(0.01, 0.99, 200)\n","f1_scores = [(thr, f1_score(y_validation, (val_proba >= thr).astype(int)))\n","             for thr in thresholds]\n","\n","best_thr, best_f1 = max(f1_scores, key=lambda x: x[1])\n","\n","print(f\"Best threshold on validation: {best_thr:.3f}\")\n","print(f\"F1 on validation with best threshold: {best_f1:.4f}\")\n","\n","def predict_with_threshold(model, X, thr=best_thr):\n","    proba = model.predict_proba(X)[:, 1]\n","    return (proba >= thr).astype(int)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0mngPsvH81-1","outputId":"83800aac-a44b-4328-c4da-fac190cc443c","executionInfo":{"status":"ok","timestamp":1763474041542,"user_tz":180,"elapsed":295,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}}},"id":"0mngPsvH81-1","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Best threshold on validation: 0.394\n","F1 on validation with best threshold: 0.8006\n"]}]},{"cell_type":"markdown","id":"231f707f","metadata":{"id":"231f707f"},"source":["## Predicciones en el conjunto de test"]},{"cell_type":"code","execution_count":14,"id":"d584f85f","metadata":{"id":"d584f85f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763474058210,"user_tz":180,"elapsed":3751,"user":{"displayName":"FRANCO ALEXIS GUARDIA","userId":"14649028846356962196"}},"outputId":"63d2b383-39d2-4e60-f1b8-b5916f5b9650"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-718284583.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  df_copy['has_time_reference']= t.str.contains(r'\\b(now|today|tonight|yesterday|urgent|breaking)\\b').astype(int)\n","/tmp/ipython-input-718284583.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n","  df_copy['elongated_token'] = t.str.contains(r'(.)\\1\\1+').astype(int)\n"]},{"output_type":"stream","name":"stdout","text":["Dimensiones del conjunto de test (antes de selección): (3263, 69199)\n","Dimensiones del conjunto de test (después de selección): (3263, 69199)\n","\n","Archivo 'submission_naive_bayes.csv' creado exitosamente!\n","Distribución de predicciones: 0    2001\n","1    1262\n","Name: count, dtype: int64\n"]}],"source":["testeo['text'] = testeo['text'].apply(preprocess_text)\n","testeo['keyword'] = testeo['keyword'].apply(preprocess_keyword)\n","testeo['location'] = testeo['location'].apply(preprocess_location)\n","\n","testeo = create_numeric_features(testeo)\n","testeo = create_categorical_features(testeo)\n","\n","testeo['text_str'] = testeo['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n","\n","X_test_tfidf = tfidf.transform(testeo['text_str'])\n","X_test_char = char_tfidf.transform(testeo['text_str'])\n","\n","X_test_kw = testeo['keyword'].where(testeo['keyword'].isin(top_keywords), 'OTHER')\n","kw_test_dum = pd.get_dummies(X_test_kw, prefix='kw', drop_first=False)\n","\n","for c in kw_train_dum.columns:\n","    if c not in kw_test_dum.columns:\n","        kw_test_dum[c] = 0\n","kw_test_dum = kw_test_dum[kw_train_dum.columns]\n","KW_test = csr_matrix(kw_test_dum.values.astype(int))\n","\n","testeo['location_mean_encoded'] = testeo['location'].apply(\n","    lambda x: mean_encode_with_smoothing(x, location_means, global_mean, smoothing, X_train, 'location')\n",")\n","\n","testeo['keyword_mean_encoded'] = testeo['keyword'].apply(\n","    lambda x: mean_encode_with_smoothing(x, keyword_means, global_mean, smoothing, X_train, 'keyword')\n",")\n","\n","X_test_num_binned = kbd.transform(testeo[numeric_features].values)\n","\n","X_test_combined = hstack([\n","    X_test_tfidf,\n","    X_test_char,\n","    KW_test,\n","    X_test_num_binned\n","])\n","\n","print(f\"Dimensiones del conjunto de test (antes de selección): {X_test_combined.shape}\")\n","\n","X_test_combined = selector.transform(X_test_combined)\n","print(f\"Dimensiones del conjunto de test (después de selección): {X_test_combined.shape}\")\n","\n","predictions = predict_with_threshold(best_model, X_test_combined, best_thr)\n","\n","submission = pd.DataFrame({\n","    'id': testeo['id'],\n","    'target': predictions\n","})\n","\n","submission.to_csv('submission_naive_bayes.csv', index=False)\n","print(\"\\nArchivo 'submission_naive_bayes.csv' creado exitosamente!\")\n","print(f\"Distribución de predicciones: {pd.Series(predictions).value_counts()}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}